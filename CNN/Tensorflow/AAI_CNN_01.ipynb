{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn.utils import shuffle           \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Adho Mukha Svanasana',\n",
    "               'Adho Mukha Vrksasana',\n",
    "               'Anjaneyasana',\n",
    "               'Ardha Chandrasana',\n",
    "               'Ardha Matsyendrasana',\n",
    "               'Ardha Navasana',\n",
    "               'Ardha Pincha Mayurasana',\n",
    "               'Baddha Konasana',\n",
    "               'Bakasana',\n",
    "               'Balasana',\n",
    "               'Bitilasana',\n",
    "               'Camatkarasana',\n",
    "               'Dhanurasana',\n",
    "               'Eka Pada Rajakapotasana',\n",
    "               'Garudasana',\n",
    "               'Halasana',\n",
    "               'Hanumanasana',\n",
    "               'Malasana',\n",
    "               'Marjaryasana',\n",
    "               'Navasana',\n",
    "               'Padmasana',\n",
    "               'Parsva Virabhadrasana',\n",
    "               'Parsvottanasana',\n",
    "               'Paschimottanasana',\n",
    "               'Phalakasana',\n",
    "               'Pincha Mayurasana',\n",
    "               'Salamba Bhujangasana',\n",
    "               'Salamba Sarvangasana',\n",
    "               'Setu Bandha Sarvangasana',\n",
    "               'Sivasana',\n",
    "               'Supta Kapotasana',\n",
    "               'Trikonasana',\n",
    "               'Upavistha Konasana',\n",
    "               'Urdhva Dhanurasana',\n",
    "               'Urdhva Mukha Svsnssana',\n",
    "               'Ustrasana',\n",
    "               'Utkata Konasana',\n",
    "               'Utkatasana',\n",
    "               'Uttanasana',\n",
    "               'Utthita Hasta Padangusthasana',\n",
    "               'Utthita Parsvakonasana',\n",
    "               'Vasisthasana',\n",
    "               'Virabhadrasana One',\n",
    "               'Virabhadrasana Three',\n",
    "               'Virabhadrasana Two',\n",
    "               'Vrksasana',\n",
    "               ]\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "IMAGE_SIZE = (150,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "   \n",
    "    datasets = [\"01_CodeProjects\\02_Data\\Train\", \"01_CodeProjects\\02_Data\\Test\"]\n",
    "    output = []\n",
    "    \n",
    "    # Iterate through the training and test set.\n",
    "    for dataset in datasets:\n",
    "        \n",
    "        images = [] \n",
    "        labels = []\n",
    "        \n",
    "        print(\"Loading {}\".format(dataset))\n",
    "        \n",
    "        # Iterate through each Subfolder corresponding to a category  \n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "            \n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "                \n",
    "                # Image path should be obtained\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "                \n",
    "                # Open and resize the img\n",
    "                image = cv.imread(img_path)\n",
    "                image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "                image = cv.resize(image, IMAGE_SIZE) \n",
    "                \n",
    "                # Append the image along with its label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')\n",
    "        \n",
    "        # Shuffle the images to introduce some randomness in our data\n",
    "        images, labels = shuffle(images, labels)\n",
    "        \n",
    "        \n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_counts = np.unique(train_labels, return_counts=True)\n",
    "_, test_counts = np.unique(test_labels, return_counts=True)\n",
    "pd.DataFrame({'train': train_counts,'test': test_counts}, index=class_names).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size = 28, epochs=15, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(history):\n",
    "\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_acc\")\n",
    "    plt.title(\"Training_accuracy vs Validation_accuracy\")\n",
    "    plt.ylabel(\"ACCURACY\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss_function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"Training_loss vs Validation_loss\")\n",
    "    plt.ylabel(\"LOSS\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n",
    "pred_labels = np.argmax(predictions,axis=1)  # np.argmax is used since each prediction would be an array of...\n",
    "                                             # probabilities and we need to pick the max value. \n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5, figsize = (15,15))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i in range(0,25):  \n",
    "    ax[i].imshow(test_images[i])\n",
    "    ax[i].set_title(f\"predicted class: {class_names[pred_labels[i]]} \\n Actual Class: {class_names[test_labels[i]]}\")\n",
    "    ax[i].axis('off')\n",
    "plt.subplots_adjust(wspace=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
