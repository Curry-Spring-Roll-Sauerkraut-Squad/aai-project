import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from sklearn.utils.class_weight import compute_class_weight

# Old Dataset
# data_dir = 'Datasets/Edited'
# New Dataset
data_dir = 'Dataset/Edited_Enhanced'

# Image Parameters
img_height, img_width = 150, 150
batch_size = 32
epochs = 100

# Image Data Preparations and Adaption
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    rotation_range=20,  # Reduce rotation range
    width_shift_range=0.1,  # Reduce shift range
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1
)

# Loading Training and Validation Data
train_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

validation_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

# Class Weight Computation
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_generator.classes),
    y=train_generator.classes
)
class_weights = dict(enumerate(class_weights))

# Epoch Step Define
steps_per_epoch = train_generator.samples // batch_size
validation_steps = validation_generator.samples // batch_size

# Tensorflow Dataset Creation
# Training
train_dataset = tf.data.Dataset.from_generator(
    lambda: train_generator,
    output_signature=(tf.TensorSpec(shape=(None, img_height, img_width, 3), dtype=tf.float32),
                      tf.TensorSpec(shape=(None, train_generator.num_classes), dtype=tf.float32))
).repeat()

# Validation
validation_dataset = tf.data.Dataset.from_generator(
    lambda: validation_generator,
    output_signature=(tf.TensorSpec(shape=(None, img_height, img_width, 3), dtype=tf.float32),
                      tf.TensorSpec(shape=(None, validation_generator.num_classes), dtype=tf.float32))
).repeat()

# Build the Model & Architecture
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(256, activation='relu'),  # Reduce dense layer size
    Dropout(0.5),
    Dense(train_generator.num_classes, activation='softmax')
])

# Model Compilation
model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('vgg16_pretrained_checkpoint.keras', save_best_only=True, monitor='val_loss')

# Model Training
history = model.fit(
    train_dataset,
    steps_per_epoch=steps_per_epoch,
    validation_data=validation_dataset,
    validation_steps=validation_steps,
    epochs=epochs,
    class_weight=class_weights,
    callbacks=[early_stopping, model_checkpoint]
)

# Model Evaluation
loss, accuracy = model.evaluate(validation_generator)
print(f'Validation accuracy: {accuracy * 100:.2f}%')

# Model Saving
model.save('vgg16_pretrained.h5')


# VGG16:
# 1. Architecture: VGG16 is a deep neural network known for its simplicity, consisting of 16 layers including convolutional and fully connected layers.
# 2. Layers: It uses a stack of convolutional layers followed by max-pooling layers to extract features, ending with three fully connected layers for classification.
# 3. Performance: Effective for image classification tasks, VGG16 achieves good accuracy but requires a large number of parameters (138 million).
# 4. Pre-training: Typically pre-trained on ImageNet, making it useful for transfer learning to tasks with similar data characteristics.
# 5. Use Case: Suitable for tasks where high accuracy is crucial but computational resources are sufficient to handle its depth and parameter count.
