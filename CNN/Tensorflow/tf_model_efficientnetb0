import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.optimizers import Adam
from sklearn.utils.class_weight import compute_class_weight
import matplotlib.pyplot as plt
from PIL import Image

# Old Dataset
# data_dir = 'Datasets/Edited'
# New Dataset
data_dir = 'Dataset/Edited_Enhanced'

# Image Parameters
img_height, img_width = 224, 224
batch_size = 32
epochs = 100

# Image Data Preparations and Adaption 
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    rotation_range=45,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2
)

# Loading Training and Validation Data
train_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

validation_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

# Pre-trained EfficientNetB0 Model
base_model = EfficientNetB0(input_shape=(img_height, img_width, 3), include_top=False, weights='imagenet')
base_model.trainable = False

model = Sequential([
    base_model,
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(train_generator.num_classes, activation='softmax')
])

# Model Compilation
model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('efficientnetb0_checkpoint.keras', save_best_only=True, monitor='val_loss')

# Model Training
train_ds = tf.data.Dataset.from_generator(
    lambda: train_generator,
    output_types=(tf.float32, tf.float32),
    output_shapes=([None, img_height, img_width, 3], [None, train_generator.num_classes])
).repeat()

val_ds = tf.data.Dataset.from_generator(
    lambda: validation_generator,
    output_types=(tf.float32, tf.float32),
    output_shapes=([None, img_height, img_width, 3], [None, validation_generator.num_classes])
).repeat()

history = model.fit(
    train_ds,
    steps_per_epoch=train_generator.samples // batch_size,
    validation_data=val_ds,
    validation_steps=validation_generator.samples // batch_size,
    epochs=epochs,
    callbacks=[early_stopping, model_checkpoint],
    verbose=1
)

# Model Evaluation
loss, accuracy = model.evaluate(validation_generator)
print(f'Validation accuracy: {accuracy * 100:.2f}%')

# Model Saving
model.save('cnn_efficientnetb0.keras')

# Current Accuracy
print(f'Current accuracy: {accuracy * 100:.2f}%')


# EfficientNetB0:
# 1. Architecture: EfficientNetB0 is designed using a balanced scaling of model depth, width, and resolution, optimizing both performance and computational cost.
# 2. Efficiency: It achieves competitive accuracy on image tasks while using fewer computational resources compared to older architectures.
# 3. Parameters: With 5.3 million parameters, EfficientNetB0 is lighter and more efficient than traditional deep networks like VGG16.
# 4. Performance: Well-suited for scenarios where computational resources are limited, such as deployment on mobile devices or edge computing environments.
# 5. Use Case: Ideal for applications requiring efficient processing without sacrificing much on accuracy, such as mobile image recognition or real-time applications.
